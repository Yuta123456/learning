{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # GPUデバイスを取得\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # CPUデバイスを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "テキスト処理のモデル\n",
    "\"\"\"\n",
    "class CaptionEncoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.bert = AutoModel.from_pretrained(\"cl-tohoku/bert-base-japanese-v2\")\n",
    "  def forward(self, x):\n",
    "    x = self.bert(x)\n",
    "    x = torch.max(x.last_hidden_state, dim=1)[0]  # max pooling\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name =  'caption_image_2023-06-28.pth'\n",
    "caption_model = CaptionEncoder().to(device)\n",
    "caption_model.load_state_dict(torch.load(model_name))\n",
    "caption_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDataset(Dataset):\n",
    "    def __init__(self, annotations_file):\n",
    "        self.data = pd.read_csv(annotations_file) \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        caption = self.data.iloc[idx, 1]\n",
    "        return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FDataset('./data/anotation_new.csv')\n",
    "dataloader =  DataLoader(dataset, batch_size=256, shuffle=False, pin_memory=True, num_workers=0)\n",
    "caption_embeddings = torch.Tensor([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (cap) in enumerate(dataloader):\n",
    "    # 予測と損失の計算\n",
    "    cap = cap.to(device)\n",
    "    with torch.no_grad():\n",
    "        caption_embedding = caption_model(cap).cpu()\n",
    "    caption_embeddings = torch.cat((caption_embeddings, caption_embedding), dim=0)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"finish: {len(caption_embeddings) * 100/len(dataset)}%\")\n",
    "\n",
    "torch.save(caption_embeddings, f'caption_tensor/{model_name[:-3]}/resnet50_tensor.pt')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
