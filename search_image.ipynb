{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from util_class.ImageStruct import ImageStruct\n",
    "import heapq\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file, tensor_file = \\\n",
    "      './data/anotation_new.csv', './image_tensor/model_image_2023-07-02/resnet50_tensor.pt'\n",
    "images = ImageStruct(annotation_file, tensor_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ジャケット × 黒（ブラック）'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_index = random.randint(0, len(images))\n",
    "s_img_tensor, s_img_path, s_category, _ = images.get(src_index)\n",
    "s_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "1.0 %\n",
      "2.0 %\n",
      "3.0 %\n",
      "4.0 %\n",
      "5.0 %\n",
      "6.0 %\n",
      "7.0 %\n",
      "8.0 %\n",
      "9.0 %\n",
      "10.0 %\n",
      "11.0 %\n",
      "12.0 %\n",
      "13.0 %\n",
      "14.0 %\n",
      "15.0 %\n",
      "16.0 %\n",
      "17.0 %\n",
      "18.0 %\n",
      "19.0 %\n",
      "20.0 %\n",
      "21.0 %\n",
      "22.0 %\n",
      "23.0 %\n",
      "24.0 %\n",
      "25.0 %\n",
      "26.0 %\n",
      "27.0 %\n",
      "28.0 %\n",
      "29.0 %\n",
      "30.0 %\n",
      "31.0 %\n",
      "32.0 %\n",
      "33.0 %\n",
      "34.0 %\n",
      "35.0 %\n",
      "36.0 %\n",
      "37.0 %\n",
      "38.0 %\n",
      "39.0 %\n",
      "40.0 %\n",
      "41.0 %\n",
      "42.0 %\n",
      "43.0 %\n",
      "44.0 %\n",
      "45.0 %\n",
      "46.0 %\n",
      "47.0 %\n",
      "48.0 %\n",
      "49.0 %\n",
      "50.0 %\n",
      "51.0 %\n",
      "52.0 %\n",
      "53.0 %\n",
      "54.0 %\n",
      "55.0 %\n",
      "56.0 %\n",
      "57.0 %\n",
      "58.0 %\n",
      "59.0 %\n",
      "60.0 %\n",
      "61.0 %\n",
      "62.0 %\n",
      "63.0 %\n",
      "64.0 %\n",
      "65.0 %\n",
      "66.0 %\n",
      "67.0 %\n",
      "68.0 %\n",
      "69.0 %\n",
      "70.0 %\n",
      "71.0 %\n",
      "72.0 %\n",
      "73.0 %\n",
      "74.0 %\n",
      "75.0 %\n",
      "76.0 %\n",
      "77.0 %\n",
      "78.0 %\n",
      "79.0 %\n",
      "80.0 %\n",
      "81.0 %\n",
      "82.0 %\n",
      "83.0 %\n",
      "84.0 %\n",
      "85.0 %\n",
      "86.0 %\n",
      "87.0 %\n",
      "88.0 %\n",
      "89.0 %\n",
      "90.0 %\n",
      "91.0 %\n",
      "92.0 %\n",
      "93.0 %\n",
      "94.0 %\n",
      "95.0 %\n",
      "96.0 %\n",
      "97.0 %\n",
      "98.0 %\n",
      "99.0 %\n",
      "(-1.2161966562271118, 'D:/M1/fashion/IQON/IQON3000\\\\1141812\\\\3806975/16551442_m.jpg')\n",
      "(-1.2127004861831665, 'D:/M1/fashion/IQON/IQON3000\\\\1251410\\\\2624247/5857075_m.jpg')\n",
      "(-1.1966805458068848, 'D:/M1/fashion/IQON/IQON3000\\\\1133542\\\\4072238/38744898_m.jpg')\n",
      "(-1.2122687101364136, 'D:/M1/fashion/IQON/IQON3000\\\\1068535\\\\3383325/10013950_m.jpg')\n",
      "(-1.1899151802062988, 'D:/M1/fashion/IQON/IQON3000\\\\1204455\\\\3976318/25639999_m.jpg')\n",
      "(-1.173323154449463, 'D:/M1/fashion/IQON/IQON3000\\\\1152237\\\\3367003/9501696_m.jpg')\n",
      "(-1.162275791168213, 'D:/M1/fashion/IQON/IQON3000\\\\104853\\\\2945344/4950720_m.jpg')\n",
      "(-1.2122687101364136, 'D:/M1/fashion/IQON/IQON3000\\\\1068535\\\\3403176/10013950_m.jpg')\n",
      "(-1.162275791168213, 'D:/M1/fashion/IQON/IQON3000\\\\1094014\\\\3011306/4950720_m.jpg')\n",
      "(-1.162275791168213, 'D:/M1/fashion/IQON/IQON3000\\\\1194228\\\\2364978/4950720_m.jpg')\n"
     ]
    }
   ],
   "source": [
    "heap = []\n",
    "MAX = 100000\n",
    "for i in range(MAX):\n",
    "    if (i % 1000 == 0):\n",
    "        print(f\"{i * 100 / MAX} %\")\n",
    "    # img_tensor, img_path, category\n",
    "    t_img_tensor, t_img_path, t_category, _ = images.get(i)\n",
    "    # print(s_category, t_category)\n",
    "    # if (s_category != t_category):\n",
    "    #     continue\n",
    "    dist = torch.dist(s_img_tensor, t_img_tensor, p=2)\n",
    "    heapq.heappush(heap, (-dist.item(), t_img_path))\n",
    "    if (len(heap) > 10):\n",
    "        heapq.heappop(heap)\n",
    "    \n",
    "for i in range(len(heap)):\n",
    "    print(heap[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.save_combined_image import save_combined_image\n",
    "\n",
    "\n",
    "save_combined_image(s_img_path, [i[1] for i in heap], f'./result/07-02/black_jacket/normal.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
