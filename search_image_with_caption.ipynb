{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from util_class.ImageStruct import ImageStruct\n",
    "import heapq\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file, tensor_file = \\\n",
    "      './data/anotation_new.csv', './image_tensor/model_image_2023-06-28/resnet50_tensor.pt'\n",
    "images = ImageStruct(annotation_file, tensor_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('レッグウェア × 灰色（グレー）',\n",
       " ' ベーシックなソリッドタイツ。トレンドに左右されない秋冬のマストアイテムです。股上深めのシルエットなので、腰もしっかりあたためてくれます。')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_index = random.randint(0, len(images))\n",
    "s_img_tensor, s_img_path, s_category, s_caption = images.get(src_index)\n",
    "s_category, s_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-v2 were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # GPUデバイスを取得\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # CPUデバイスを取得\n",
    "\"\"\"\n",
    "テキスト処理のモデル\n",
    "\"\"\"\n",
    "class CaptionEncoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.bert = AutoModel.from_pretrained(\"cl-tohoku/bert-base-japanese-v2\")\n",
    "  def forward(self, x):\n",
    "    x = self.bert(x)\n",
    "    x = torch.max(x.last_hidden_state, dim=1)[0]  # max pooling\n",
    "    return x\n",
    "\n",
    "model_name =  './model/model_caption_2023-06-28.pth'\n",
    "caption_model = CaptionEncoder().to(device)\n",
    "caption_model.load_state_dict(torch.load(model_name))\n",
    "caption_model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = tokenizer.encode(\"冬、寒い、フォーマル、アウター、上品、高級\", return_tensors='pt')\n",
    "ids = ids.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_caption_tensor = caption_model(ids)[0].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.category import get_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "1.0 %\n",
      "2.0 %\n",
      "3.0 %\n",
      "4.0 %\n",
      "5.0 %\n",
      "6.0 %\n",
      "7.0 %\n",
      "8.0 %\n",
      "9.0 %\n",
      "10.0 %\n",
      "11.0 %\n",
      "12.0 %\n",
      "13.0 %\n",
      "14.0 %\n",
      "15.0 %\n",
      "16.0 %\n",
      "17.0 %\n",
      "18.0 %\n",
      "19.0 %\n",
      "20.0 %\n",
      "21.0 %\n",
      "22.0 %\n",
      "23.0 %\n",
      "24.0 %\n",
      "25.0 %\n",
      "26.0 %\n",
      "27.0 %\n",
      "28.0 %\n",
      "29.0 %\n",
      "30.0 %\n",
      "31.0 %\n",
      "32.0 %\n",
      "33.0 %\n",
      "34.0 %\n",
      "35.0 %\n",
      "36.0 %\n",
      "37.0 %\n",
      "38.0 %\n",
      "39.0 %\n",
      "40.0 %\n",
      "41.0 %\n",
      "42.0 %\n",
      "43.0 %\n",
      "44.0 %\n",
      "45.0 %\n",
      "46.0 %\n",
      "47.0 %\n",
      "48.0 %\n",
      "49.0 %\n",
      "50.0 %\n",
      "51.0 %\n",
      "52.0 %\n",
      "53.0 %\n",
      "54.0 %\n",
      "55.0 %\n",
      "56.0 %\n",
      "57.0 %\n",
      "58.0 %\n",
      "59.0 %\n",
      "60.0 %\n",
      "61.0 %\n",
      "62.0 %\n",
      "63.0 %\n",
      "64.0 %\n",
      "65.0 %\n",
      "66.0 %\n",
      "67.0 %\n",
      "68.0 %\n",
      "69.0 %\n",
      "70.0 %\n",
      "71.0 %\n",
      "72.0 %\n",
      "73.0 %\n",
      "74.0 %\n",
      "75.0 %\n",
      "76.0 %\n",
      "77.0 %\n",
      "78.0 %\n",
      "79.0 %\n",
      "80.0 %\n",
      "81.0 %\n",
      "82.0 %\n",
      "83.0 %\n",
      "84.0 %\n",
      "85.0 %\n",
      "86.0 %\n",
      "87.0 %\n",
      "88.0 %\n",
      "89.0 %\n",
      "90.0 %\n",
      "91.0 %\n",
      "92.0 %\n",
      "93.0 %\n",
      "94.0 %\n",
      "95.0 %\n",
      "96.0 %\n",
      "97.0 %\n",
      "98.0 %\n",
      "99.0 %\n",
      "(-18.912038803100586, 'D:/M1/fashion/IQON/IQON3000\\\\1110748\\\\1834204/4789523_m.jpg')\n",
      "(-18.909568786621094, 'D:/M1/fashion/IQON/IQON3000\\\\1029943\\\\3021602/8422091_m.jpg')\n",
      "(-18.90789222717285, 'D:/M1/fashion/IQON/IQON3000\\\\1110748\\\\2141117/5150505_m.jpg')\n",
      "(-18.907625198364258, 'D:/M1/fashion/IQON/IQON3000\\\\1011659\\\\3293660/9607464_m.jpg')\n",
      "(-18.90736198425293, 'D:/M1/fashion/IQON/IQON3000\\\\1198908\\\\3433140/10172971_m.jpg')\n",
      "(-18.904953002929688, 'D:/M1/fashion/IQON/IQON3000\\\\1129711\\\\3912848/36160392_m.jpg')\n",
      "(-18.90428352355957, 'D:/M1/fashion/IQON/IQON3000\\\\1073968\\\\1655231/2675382_m.jpg')\n",
      "(-18.90565299987793, 'D:/M1/fashion/IQON/IQON3000\\\\1057034\\\\2875144/5396488_m.jpg')\n",
      "(-18.905994415283203, 'D:/M1/fashion/IQON/IQON3000\\\\1220149\\\\4045786/39422471_m.jpg')\n",
      "(-18.90125274658203, 'D:/M1/fashion/IQON/IQON3000\\\\1103160\\\\3614533/11173322_m.jpg')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "heap = []\n",
    "MAX = 100000\n",
    "for i in range(MAX):\n",
    "    if (i % 1000 == 0):\n",
    "        print(f\"{i * 100 / MAX} %\")\n",
    "    # img_tensor, img_path, category\n",
    "    t_img_tensor, t_img_path, t_category, _ = images.get(i)\n",
    "    t_id = get_item_id(t_img_path)\n",
    "    heap_ids = [get_item_id(i[1]) for i in heap]\n",
    "    if (t_id in heap_ids):\n",
    "        continue\n",
    "    # print(s_category, t_category)\n",
    "    # if (s_category != t_category):\n",
    "    #     continue\n",
    "    dist = torch.dist(s_caption_tensor, t_img_tensor, p=2)\n",
    "    heapq.heappush(heap, (-dist.item(), t_img_path))\n",
    "    if (len(heap) > 10):\n",
    "        heapq.heappop(heap)\n",
    "    \n",
    "for i in range(len(heap)):\n",
    "    print(heap[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.save_combined_image import save_combined_image\n",
    "\n",
    "\n",
    "save_combined_image(s_img_path, [i[1] for i in heap], f'./result/caption/test4.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
